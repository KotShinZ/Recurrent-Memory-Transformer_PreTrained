{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RecurrentMemoryTransformer Training using Huggingface Trainer\n",
    "\n",
    "This notebook demonstrates how to train RecurrentMemoryTransformer model using Huggingface Trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    AutoTokenizer, \n",
    "    AutoConfig, \n",
    "    AutoModelForCausalLM,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Import RecurrentMemoryTransformer modules\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "from recurrent_memory_transformer.RecurrentMemoryTransformer import RecurrentMemoryTransformer\n",
    "from recurrent_memory_transformer.PreTrainedRMTConfig import PreTrainedRMTConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Parameter Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset path and model parameters setup\n",
    "dataset_path = \"HuggingFaceFW/fineweb-edu\"\n",
    "dataset_name = \"CC-MAIN-2024-10\"\n",
    "\n",
    "# Base model setup\n",
    "base_model_name = \"gpt2\"  # Can be changed to any base model\n",
    "\n",
    "# RMT parameters\n",
    "is_memory_all = True\n",
    "max_n_segments = 3\n",
    "input_seg_len = 512\n",
    "output_seg_len = 512\n",
    "align = \"left\"\n",
    "num_mem_tokens = 10\n",
    "\n",
    "# Training parameters\n",
    "output_dir = \"./rmt_model_output\"\n",
    "learning_rate = 5e-5\n",
    "per_device_train_batch_size = 4\n",
    "per_device_eval_batch_size = 4\n",
    "num_train_epochs = 0.1\n",
    "max_seq_length = 1024\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Preprocessing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# データセットのロード\n",
    "dataset = load_dataset(dataset_path, dataset_name)\n",
    "\n",
    "dataset['train'] = dataset['train'].train_test_split(test_size=0.999, seed=42)['train']\n",
    "if  \"test\" not in dataset:\n",
    "    try:\n",
    "        dataset = dataset[\"train\"].train_test_split(test_size=100, seed=42)\n",
    "    except:\n",
    "        dataset = dataset.train_test_split(test_size=100, seed=42)\n",
    "            \n",
    "print(f\"Dataset loaded: {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トークナイザーのロード\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# データセットの前処理関数\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], \n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_seq_length\n",
    "    )\n",
    "\n",
    "# データセットの前処理\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=[col for col in dataset[\"train\"].column_names if col != \"text\"],\n",
    "    desc=\"Tokenizing dataset\",\n",
    ")\n",
    "\n",
    "# データセットのフォーマットを設定\n",
    "tokenized_dataset = tokenized_dataset.with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize RecurrentMemoryTransformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# ベースモデルの設定をロード\n",
    "base_config = AutoConfig.from_pretrained(base_model_name)\n",
    "\n",
    "# RecurrentMemoryTransformerの設定を作成\n",
    "rmt_config = PreTrainedRMTConfig(\n",
    "    base_model_config=base_config,\n",
    "    base_model_type=base_model_name,\n",
    "    is_memory_all=is_memory_all,\n",
    "    max_n_segments=max_n_segments,\n",
    "    input_seg_len=input_seg_len,\n",
    "    output_seg_len=output_seg_len,\n",
    "    align=align,\n",
    "    num_mem_tokens=num_mem_tokens\n",
    ")\n",
    "\n",
    "# ベースモデルをロード\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model_name)\n",
    "\n",
    "# RecurrentMemoryTransformerモデルを初期化\n",
    "model = RecurrentMemoryTransformer(rmt_config, base_model=base_model)\n",
    "print(f\"Model initialized with config: {rmt_config}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collator Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データコレーター（言語モデリング用）の設定\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # MLMではなくCLMを使用\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer Setup and Training Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# トレーニング引数の設定\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=per_device_eval_batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=os.path.join(output_dir, \"logs\"),\n",
    "    logging_steps=100,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    fp16=torch.cuda.is_available(),  # GPUが利用可能なら半精度で学習\n",
    "    gradient_accumulation_steps=2,   # 勾配蓄積ステップ\n",
    ")\n",
    "\n",
    "# Trainerの初期化\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"] if \"test\" in tokenized_dataset else None,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# モデルの学習を実行\n",
    "print(\"Starting training...\")\n",
    "train_result = trainer.train()\n",
    "\n",
    "# 学習結果と指標の表示\n",
    "print(f\"Training metrics: {train_result.metrics}\")\n",
    "\n",
    "# モデルの保存\n",
    "trainer.save_model()\n",
    "print(f\"Model saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの評価（検証データセットがある場合）\n",
    "if \"validation\" in tokenized_dataset:\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"Evaluation results: {eval_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Test text generation\n",
    "test_input = \"Today is a wonderful day.\"\n",
    "inputs = tokenizer(test_input, return_tensors=\"pt\").to(device)\n",
    "out = model.generate(input_ids = inputs[\"input_ids\"], max_length=50)\n",
    "out_text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "print(out_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openr1_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
